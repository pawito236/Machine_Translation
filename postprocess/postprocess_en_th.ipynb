{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "easUa6J_x9s0"
      },
      "source": [
        "#Postprocess Real test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc7rvPB6BXuO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhY9YEIByFRj"
      },
      "outputs": [],
      "source": [
        "def preprocessTest_en(df):\n",
        "  '''\n",
        "  drop Nan\n",
        "  replace \"Alright!\" -> \"Alright !\", \"Goodnight.\" -> \"Goodnight .\" เว้นจุด ! ? ที่ท้ายประโยค\n",
        "  replace \"Alright, bye\" -> \"Alright , bye\"\n",
        "  replace \"&quot;\" -> '\"' (ฟันหนู)\n",
        "  '''\n",
        "  df = df.dropna()\n",
        "\n",
        "  df['en_text'] = df['en_text'].map(lambda x: x[:-1] + ' .' if x.endswith('.')  else x)\n",
        "  df['en_text'] = df['en_text'].map(lambda x: x[:-1] + ' ?' if x.endswith('?')  else x)\n",
        "  df['en_text'] = df['en_text'].map(lambda x: x[:-1] + ' !' if x.endswith('!')  else x)\n",
        "\n",
        "  E_idx = df[(df['en_text'].str.contains(',') == True) & (df['en_text'].str.contains(', ') == True)& (df['en_text'].str.contains(' ,') == False)].index\n",
        "  df['en_text'][E_idx] = df[(df['en_text'].str.contains(',') == True) & (df['en_text'].str.contains(', ') == True)& (df['en_text'].str.contains(' ,') == False)]['en_text'].str.replace(\",\", \" ,\")\n",
        "\n",
        "  df['en_text'].map(lambda x : re.sub('&quot;','\\\"',x))\n",
        "\n",
        "  Test_df['en_post'] = Test_df['en_post'].map(lambda x : re.sub('i ','I ',x))\n",
        "  Test_df['en_post'] = Test_df['en_post'].map(lambda x : re.sub(\"i'\",\"I'\",x))\n",
        "  Test_df['en_post'] = Test_df['en_post'].map(lambda x : re.sub(\" i[.]\",\" I.\",x))\n",
        "  Test_df['en_post'] = Test_df['en_post'].map(lambda x : re.sub(\" i\",\" I\",x))\n",
        "  Test_df['en_post'] = Test_df['en_post'].map(lambda x : re.sub(\"(?<=[a-z])I\",\"i\",x))\n",
        "  Test_df['en_post'] = Test_df['en_post'].map(lambda x : re.sub(\"I(?=[a-z])\",\"i\",x))\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y5ZmLodyKES"
      },
      "outputs": [],
      "source": [
        "def postprocessTest_en(df):\n",
        "  '''\n",
        "  hello . -> hello.\n",
        "  เติม จุด ให้ถ้าไม่ใช่คำถาม\n",
        "  wh-qustion to end with ?\n",
        "\n",
        "  '''\n",
        "  df = df.dropna()\n",
        "  # add . \n",
        "  df['en_text'] = df['en_text'].map(lambda x: x + '.' if (x[-1] != '\"' and x[-1] != '!' and x[-1] != '?' and x[-1] != '.')  else x)\n",
        "  df['en_text'] = df['en_text'].str.replace(\" \\\\.\", '.')\n",
        "  df['en_text'] = df['en_text'].str.replace(\" \\\\?\", '?')\n",
        "  df['en_text'] = df['en_text'].str.replace(\" \\\\!\", '!')\n",
        "\n",
        "  df['en_text'] = df['en_text'].str.replace(\" 'm\", \"'m\")\n",
        "  df['en_text'] = df['en_text'].str.replace(\" 's\", \"'s\")\n",
        "  df['en_text'] = df['en_text'].str.replace(\" 're\", \"'re\")\n",
        "  df['en_text'] = df['en_text'].str.replace(\" 'll\", \"'ll\")\n",
        "  df['en_text'] = df['en_text'].str.replace(\" 't\", \"'t\")\n",
        "\n",
        "  # Uppercase first sentence\n",
        "  df['en_text'] = df['en_text'].map(lambda x: str(x[0]).upper() + x[1:] if str(x[0]).isalpha()  else x)\n",
        "\n",
        "\n",
        "\n",
        "  try:\n",
        "    df['en_text'] = df['en_text'].map(lambda x: x[0] + str(x[1]).upper() + x[2:] if str(x[0]) == '\"'  else x)\n",
        "  except:\n",
        "    df['en_text'] = df['en_text']\n",
        "\n",
        "  def replace_xx(df, word, new_word, stop_word, new_stop_word):\n",
        "    idx = df[df[\"en_text\"].str.startswith(word)].index\n",
        "    df.en_text[idx] = df[df['en_text'].str.startswith(word)]['en_text'].str.replace(word, new_word)\n",
        "    idxx = df[df[\"en_text\"].str.endswith(stop_word) & df[\"en_text\"].str.startswith(new_word)].index\n",
        "    df['en_text'][idxx] = df['en_text'][idxx].map(lambda x: x[:-1] + new_stop_word if True  else x)\n",
        "    return df  \n",
        "\n",
        "  replace_xx(df,\"do \", \"Do \", \".\", \"?\")\n",
        "  replace_xx(df,\"did \", \"Did \", \".\", \"?\")\n",
        "  replace_xx(df,\"does \", \"Does \", \".\", \"?\")\n",
        "  replace_xx(df,\"what \", \"What \", \".\", \"?\")\n",
        "  replace_xx(df,\"when \", \"When \", \".\", \"?\")\n",
        "  replace_xx(df,\"where \", \"Where \", \".\", \"?\")\n",
        "  replace_xx(df,\"why \", \"Why \", \".\", \"?\")\n",
        "  replace_xx(df,\"how \", \"How \", \".\", \"?\")\n",
        "  replace_xx(df,\"can \", \"Can \", \".\", \"?\")\n",
        "  replace_xx(df,\"could \", \"Could \", \".\", \"?\")\n",
        "  replace_xx(df,\"may \", \"May \", \".\", \"?\")\n",
        "  replace_xx(df,\"might \", \"Might \", \".\", \"?\")\n",
        "\n",
        "  # startswith \"i \" -> \"I \"\n",
        "  idx = df[df[\"en_text\"].str.startswith('i ')].index\n",
        "  df.en_text[idx] = df['en_text'][idx].str.replace('i ', 'I ')\n",
        "  # \" i \" -> \" I \"\n",
        "  df['en_text'].str.replace(' i ', ' I ')\n",
        "\n",
        "  df['en_text'] = df['en_text'].map(lambda x : re.sub('i ','I ',x))\n",
        "  df['en_text'] = df['en_text'].map(lambda x : re.sub(\"i'\",\"I'\",x))\n",
        "  df['en_text'] = df['en_text'].map(lambda x : re.sub(\" i[.]\",\" I.\",x))\n",
        "  df['en_text'] = df['en_text'].map(lambda x : re.sub(\" i\",\" I\",x))\n",
        "  df['en_text'] = df['en_text'].map(lambda x : re.sub(\"(?<=[a-z])I\",\"i\",x))\n",
        "  df['en_text'] = df['en_text'].map(lambda x : re.sub(\"I(?=[a-z])\",\"i\",x))\n",
        "\n",
        "  df.en_text = df['en_text'].str.replace('\\\\.\\\\?', '?')\n",
        "  df.en_text = df['en_text'].str.replace('\\\\?\\\\?', '?')\n",
        "  df.en_text = df['en_text'].str.replace('\\\\.\\\\.\\\\.\\\\.', '<unk>')\n",
        "  df.en_text = df['en_text'].str.replace('\\\\.\\\\.', '.')\n",
        "  df.en_text = df['en_text'].str.replace('<unk>', '...')\n",
        "  df.en_text = df['en_text'].str.replace('tHe', 'the')\n",
        "  df.en_text = df['en_text'].str.replace('\"\\\\.', '\"')\n",
        "  df.en_text = df['en_text'].str.replace('เฟอร์', '')\n",
        "  df.en_text = df['en_text'].str.replace(' ลาย', '')\n",
        "  df.en_text = df['en_text'].str.replace(' จาง ', ' ')\n",
        "\n",
        "  df['en_text'] = df['en_text'].map(lambda x: str(x[0]).upper() + x[1:] if str(x[0]).isalpha()  else x)\n",
        "  \n",
        "   \n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxs66ciayUXs"
      },
      "outputs": [],
      "source": [
        "def processTest_th(df):\n",
        "  # --------------ถ้า preprocess ก่อน predict ให้รันทั้งหมด -----------------------\n",
        "  df = df.fillna(\"\")\n",
        "  def removeunderscore(df): \n",
        "    df['th_text'] = df['th_text'].str.replace(\"_\", \"\") \n",
        "    return df\n",
        "  df = removeunderscore(df)\n",
        "\n",
        "  def fill_th_q(df, word, new_word):\n",
        "    idx = df[df[\"th_text\"].str.endswith(word)].index\n",
        "    df['th_text'][idx] = df[df['th_text'].str.endswith(word)][\"th_text\"].str.replace(word, new_word)\n",
        "    return df\n",
        "\n",
        "  fill_th_q(df, \" ไหม\", \" ไหม ?\")\n",
        "  fill_th_q(df, \" อะไร\", \" อะไร ?\")\n",
        "  fill_th_q(df, \" รึยัง\", \" รึยัง ?\")\n",
        "  fill_th_q(df, \" อย่าง ไร ดี\", \" อย่าง ไร ดี ?\")\n",
        "  fill_th_q(df, \"กี่โมง\", \"กี่โมง ?\")\n",
        "\n",
        "  def dup_th(df, word, new_word):\n",
        "    idx = df[df[\"th_text\"].str.contains(word)].index\n",
        "    df.th_text[idx] = df[df['th_text'].str.contains(word)][\"th_text\"].str.replace(word, new_word)\n",
        "    return df\n",
        "\n",
        "  dup_th(df, \"มาก มาก \", \"มาก ๆ \")\n",
        "  dup_th(df, \"ทุก ทุก \", \"ทุก ๆ \")\n",
        "  dup_th(df, \"แน่ แน่ \", \"แน่ ๆ \")\n",
        "  dup_th(df, \"อื่น อื่น \", \"อื่น ๆ \")\n",
        "  dup_th(df, \"ค่อย ค่อย \", \"ค่อย ๆ \")\n",
        "  dup_th(df, \"คร่าว คร่าว \", \"คร่าว ๆ \")\n",
        "  dup_th(df, \"จิ๊บ จิ๊บ \", \"จิ๊บ ๆ \")\n",
        "  dup_th(df, \"จริง จริง \", \"จริง ๆ \")\n",
        "  dup_th(df, \"ข้าง ข้าง \", \"ข้าง ๆ \")\n",
        "\n",
        "  # ------------ถ้าทำ postprocess ต่อจากการ predict ให้คอมเม้นทั้งชุดนี้ออกไป-------------\n",
        "  # def removeunderscore(df): \n",
        "  #   df['th_Sep'] = df['th_Sep'].str.replace(\"_\", \"\") \n",
        "  #   return df\n",
        "  # df = removeunderscore(df)\n",
        "\n",
        "  # def fill_th_q(df, word, new_word):\n",
        "  #   idx = df[df[\"th_Sep\"].str.endswith(word)].index\n",
        "  #   df['th_Sep'][idx] = df[df['th_Sep'].str.endswith(word)][\"th_Sep\"].str.replace(word, new_word)\n",
        "  #   return df\n",
        "\n",
        "  # fill_th_q(df, \" ไหม\", \" ไหม ?\")\n",
        "  # fill_th_q(df, \" อะไร\", \" อะไร ?\")\n",
        "  # fill_th_q(df, \" รึยัง\", \" รึยัง ?\")\n",
        "  # fill_th_q(df, \" อย่าง ไร ดี\", \" อย่าง ไร ดี ?\")\n",
        "  # fill_th_q(df, \"กี่โมง\", \"กี่โมง ?\")\n",
        "\n",
        "  # def dup_th(df, word, new_word):\n",
        "  #   idx = df[df[\"th_Sep\"].str.contains(word)].index\n",
        "  #   df.th_Sep[idx] = df[df['th_Sep'].str.contains(word)][\"th_Sep\"].str.replace(word, new_word)\n",
        "  #   return df\n",
        "\n",
        "  # dup_th(df, \"มาก มาก \", \"มาก ๆ \")\n",
        "  # dup_th(df, \"ทุก ทุก \", \"ทุก ๆ \")\n",
        "  # dup_th(df, \"แน่ แน่ \", \"แน่ ๆ \")\n",
        "  # dup_th(df, \"อื่น อื่น \", \"อื่น ๆ \")\n",
        "  # dup_th(df, \"ค่อย ค่อย \", \"ค่อย ๆ \")\n",
        "  # dup_th(df, \"คร่าว คร่าว \", \"คร่าว ๆ \")\n",
        "  # dup_th(df, \"จิ๊บ จิ๊บ \", \"จิ๊บ ๆ \")\n",
        "  # dup_th(df, \"จริง จริง \", \"จริง ๆ \")\n",
        "  # dup_th(df, \"ข้าง ข้าง \", \"ข้าง ๆ \")\n",
        "\n",
        "  # df.drop(columns=['th_sent'])\n",
        "  # df['th_sent'] = df['th_Sep'].str.replace(\" \", \"\")\n",
        "  # -------------------------------------------------------------\n",
        "\n",
        "  return df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "process_testset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
